# Air Quality Index (AQI) Prediction Project

A machine learning project to predict Air Quality Index (AQI) using weather and pollutant data with an interactive Streamlit dashboard.

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- pip

### Installation

1. **Clone the repository:**
```bash
git clone <repository-url>
cd data_science_project
```

2. **Create and activate virtual environment:**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies:**
```bash
pip install -r requirements.txt
```

4. **Install the package:**
```bash
pip install -e .
```

## ğŸ“Š Running the Streamlit App

### Step 1: Verify Models Exist

Check if trained models are available:
```bash
python check_models.py
```

If models are missing, you need to train them first (see Training Models section below).

### Step 2: Run the App

```bash
streamlit run app.py
```

The app will automatically open in your browser at `http://localhost:8501`

### Using the App

1. **Enter Pollutant Values** (in sidebar):
   - CO (Carbon Monoxide) - Âµg/mÂ³
   - NO (Nitric Oxide) - Âµg/mÂ³
   - NOâ‚‚ (Nitrogen Dioxide) - Âµg/mÂ³
   - Oâ‚ƒ (Ozone) - Âµg/mÂ³
   - SOâ‚‚ (Sulfur Dioxide) - Âµg/mÂ³
   - PMâ‚‚.â‚… (Fine Particles) - Âµg/mÂ³
   - PMâ‚â‚€ (Coarse Particles) - Âµg/mÂ³
   - NHâ‚ƒ (Ammonia) - Âµg/mÂ³

2. **Set Date and Time**:
   - Year, Month, Day, Hour

3. **Click "ğŸ”® Predict AQI"** to get predictions

### App Features

- âœ… Real-time AQI prediction (regression)
- âœ… AQI category classification (Good/Satisfactory/Moderate/Poor/Very Poor)
- âœ… Health alerts for hazardous levels
- âœ… Probability distributions
- âœ… Feature importance visualization
- âœ… Color-coded AQI categories

## ğŸ¯ Training Models

If models don't exist, train them first:

1. **Open the training notebook:**
```bash
jupyter notebook notebook/Model_Training.ipynb
```

2. **Run all cells** (Cell â†’ Run All)

3. **Wait for completion** (5-15 minutes)

4. **Verify models were created:**
```bash
python check_models.py
```

Required model files:
- `final_classifier.pkl`
- `final_regressor.pkl`
- `scaler.pkl`
- `reg_scaler.pkl`

## ğŸ“ Project Structure

```
data_science_project/
â”œâ”€â”€ app.py                      # Streamlit dashboard
â”œâ”€â”€ check_models.py             # Helper to verify models
â”œâ”€â”€ config.py                   # Configuration (for future use)
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ setup.py                    # Package setup
â”‚
â”œâ”€â”€ src/                        # Source code utilities
â”‚   â”œâ”€â”€ logger.py               # Logging (used by data collection)
â”‚   â”œâ”€â”€ exception.py            # Exception handling (used by data collection)
â”‚   â”œâ”€â”€ components/              # (for future use)
â”‚   â””â”€â”€ pipeline/               # (for future use)
â”‚
â””â”€â”€ notebook/                   # Notebooks and data
    â”œâ”€â”€ EDA_AQI.ipynb          # Exploratory Data Analysis
    â”œâ”€â”€ Model_Training.ipynb   # Model training
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ data_collection.py # Data fetching script
    â”‚   â””â”€â”€ merged_aqi_data.csv # Dataset
    â”œâ”€â”€ models/                 # Trained models (.pkl files)
    â””â”€â”€ output/                 # Results and visualizations
```

## ğŸ”§ Data Collection

To fetch new data:

```bash
python notebook/data/data_collection.py
```

This will:
- Fetch data from Open-Meteo and OpenWeather APIs
- Merge data from both sources
- Save to `notebook/data/merged_aqi_data.csv`
- Only fetch new data (incremental updates)

## ğŸ“š Features

### Data Collection
- Fetches from Open-Meteo Air Quality API
- Fetches from OpenWeather Air Pollution API
- Merges and deduplicates data
- Incremental updates

### Model Training
- **Classification Models**: Decision Tree, KNN, Logistic Regression, Naive Bayes, Random Forest, Gradient Boosting, LightGBM, XGBoost
- **Regression Model**: Gradient Boosting Regressor
- Hyperparameter tuning with Optuna
- SMOTE for class imbalance handling
- Model evaluation with multiple metrics

### Exploratory Data Analysis
- Data overview and missing value analysis
- AQI distribution and trends
- Pollutant correlation analysis
- Temporal patterns (hourly, monthly, seasonal)
- Outlier detection

## ğŸ› ï¸ Troubleshooting

### Models Not Found
**Error:** `Model file not found`

**Solution:**
1. Train models: `jupyter notebook notebook/Model_Training.ipynb`
2. Run all cells
3. Verify: `python check_models.py`

### ModuleNotFoundError
**Error:** `No module named 'streamlit'`

**Solution:**
```bash
pip install -r requirements.txt
```

### Port Already in Use
**Error:** Port 8501 is already in use

**Solution:**
```bash
streamlit run app.py --server.port 8502
```

## ğŸ“ Dependencies

Key dependencies:
- `streamlit` - Web dashboard
- `pandas`, `numpy` - Data processing
- `scikit-learn`, `xgboost`, `lightgbm` - Machine learning
- `joblib` - Model serialization
- `matplotlib`, `seaborn` - Visualization

See `requirements.txt` for complete list.

## ğŸ“ Model Information

- **Classification**: Predicts AQI category (1-5)
- **Regression**: Predicts continuous AQI value
- **Features**: CO, NO, NOâ‚‚, Oâ‚ƒ, SOâ‚‚, PMâ‚‚.â‚…, PMâ‚â‚€, NHâ‚ƒ, Year, Month, Day, Hour
- **Best Models**: XGBoost (classification), Gradient Boosting (regression)

## ğŸ” Authentication & Setup

**Quick Answer**: 
- âœ… **No login required** for local usage (CSV fallback works)
- âš ï¸ **Hopsworks**: Optional - requires Python 3.12 and API key
- âš ï¸ **GitHub Actions**: Optional - requires GitHub account + secrets
- âœ… **OpenWeather API**: Required for fetching new data (configured in `.env`)

**API Keys**: Set in `.env` file:
- `OPENWEATHER_API_KEY`: Required for data collection
- `HOPSWORKS_API_KEY`: Optional (for cloud Feature Store)

## ğŸ“„ License

This project is for educational purposes.

## ğŸ‘¤ Author

Saad

---

**Quick Command Reference:**
```bash
# Check models
python check_models.py

# Run app
streamlit run app.py

# Train models (if needed)
jupyter notebook notebook/Model_Training.ipynb

# Collect data
python notebook/data/data_collection.py
```
